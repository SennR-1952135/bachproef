{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2286fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import json\n",
    "import sys\n",
    "import datetime\n",
    "import configargparse\n",
    "from utils import str2bool, str_or_none, name2dic, get_valid_types\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from tensorboardX import SummaryWriter\n",
    "from model.torchcrf import CRF\n",
    "\n",
    "from model import datasets\n",
    "from model.models_sherlock import FeatureEncoder, SherlockClassifier, build_sherlock\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# =============\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc61c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/senn/inf-bachpr-21-22-student-SennR-1952135/code/project/sato/tmp/csv-sato-p1_type78_header_valid.pkl pickle file found, loading...\n",
      "csv-sato-p1_type78_header_valid Load complete. Time 0.04062342643737793\n",
      "Total data preparation time: 9.199613094329834\n"
     ]
    }
   ],
   "source": [
    "TYPENAME = 'type78'\n",
    "valid_types = get_valid_types(TYPENAME)\n",
    "topic_name = 'num-directstr_thr-0_tn-400' #or None\n",
    "label_enc = LabelEncoder()\n",
    "label_enc.fit(valid_types)\n",
    "corpus_list = ['csv-sato-p1'] #['webtables1-p1', 'webtables2-p1'] #['csv-sato-p1']\n",
    "# corpus = corpus_list[0]\n",
    "sherlock_feature_groups = ['char', 'word', 'par', 'rest']\n",
    "MAX_COL_COUNT = 15\n",
    "whole_corpus = []\n",
    "\n",
    "for corpus in corpus_list:\n",
    "    \n",
    "    corpus_data = datasets.TableFeatures(corpus,\n",
    "                                        sherlock_feature_groups, \n",
    "                                        topic_feature=topic_name, \n",
    "                                        label_enc=label_enc, \n",
    "                                        id_filter=None,\n",
    "                                        max_col_count=MAX_COL_COUNT)\n",
    "    whole_corpus.append(corpus_data)\n",
    "\n",
    "corpus_data = None\n",
    "val_dataset = ConcatDataset(whole_corpus) #whole_corpus\n",
    "# whole_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338ad1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "({'char': tensor([[ 1.0000,  0.0000,  0.3333,  ...,  0.0000, -3.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -3.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), 'word': tensor([[-0.2313,  0.8445,  0.0347,  ...,  0.0729,  0.1239,  0.2908],\n",
      "        [-0.3253,  0.0104, -0.1658,  ...,  0.4757,  0.6145,  0.2272],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), 'par': tensor([[-0.0276,  0.0261, -0.0782,  ..., -0.0204, -0.0388, -0.0471],\n",
      "        [ 0.0003, -0.0003,  0.0007,  ...,  0.0007, -0.0011,  0.0010],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), 'rest': tensor([[ 1.5850,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  3.0000,  1.0000,  1.0000,  1.0000,\n",
      "          0.0000,  1.0000,  1.0000,  1.0000,  3.0000, -3.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 1.5850,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  5.3333,  2.0548,\n",
      "          0.0000,  0.0000,  1.6667,  0.4714,  3.0000,  1.0000,  1.0000,  6.6667,\n",
      "          8.2222,  3.0000, 10.0000,  7.0000, 20.0000, -1.5000, -0.1728,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000]]), 'topic': tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        ...,\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003],\n",
      "        [0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0003, 0.0003]])}, array([75, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8))\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataset))\n",
    "# print(val_dataset[0])\n",
    "print(val_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c684bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_group_cols = {}\n",
    "sherlock_feature_groups = ['char', 'word', 'par', 'rest']\n",
    "# for f_g in sherlock_feature_groups:\n",
    "#     feature_group_cols[f_g] = list(pd.read_csv(join(os.environ['BASEPATH'],\n",
    "#                                           'configs', 'feature_groups', \n",
    "#                                           \"{}_col.tsv\".format(f_g)),\n",
    "#                                            sep='\\t', header=None, \n",
    "#                                            index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e8be723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --model_type=CRF --model_path=CRF+LDA_pre.pt --topic=num-directstr_thr-0_tn-400\n",
    "MAX_COL_COUNT = 15\n",
    "TYPENAME = 'type78'\n",
    "n_worker = 4\n",
    "device = torch.device('cpu')\n",
    "batch_size = 100\n",
    "topic_dim = 400\n",
    "valid_types = get_valid_types(TYPENAME)\n",
    "model_path = 'CRF+LDA_pre.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d43b2fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(num_tags=78)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "classifier = build_sherlock(sherlock_feature_groups, num_classes=len(valid_types), topic_dim=topic_dim).to(device)\n",
    "model = CRF(len(valid_types) , batch_first=True).to(device)\n",
    "    \n",
    "model_loc = join(os.environ['BASEPATH'],'model','pre_trained_CRF', TYPENAME)\n",
    "loaded_params = torch.load(join(model_loc, model_path), map_location=device)\n",
    "classifier.load_state_dict(loaded_params['col_classifier'])\n",
    "model.load_state_dict(loaded_params['CRF_model'])\n",
    "\n",
    "classifier.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05cb2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and return prediction & true labels of a table batch\n",
    "def eval_batch(classifier, model, val_dataset, batch_size, device, n_worker, MAX_COL_COUNT=15):\n",
    "\n",
    "\n",
    "    validation = datasets.generate_batches(val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False, \n",
    "                                           drop_last=True,\n",
    "                                           device=device,\n",
    "                                           n_workers=n_worker)\n",
    "    y_pred, y_true = [], []\n",
    "    for table_batch, label_batch, mask_batch in tqdm(validation):\n",
    "        #pred, labels = eval_batch(table_batch, label_batch, mask_batch)\n",
    "            \n",
    "        # reshap (table_batch * table_size * features)\n",
    "        for f_g in table_batch:\n",
    "            table_batch[f_g] = table_batch[f_g].view(batch_size * MAX_COL_COUNT, -1)\n",
    "\n",
    "        emissions = classifier(table_batch).view(batch_size, MAX_COL_COUNT, -1)\n",
    "        pred = model.decode(emissions, mask_batch)\n",
    "\n",
    "        pred = np.concatenate(pred)\n",
    "        labels = label_batch.view(-1).cpu().numpy()\n",
    "        masks = mask_batch.view(-1).cpu().numpy()\n",
    "        invert_masks = np.invert(masks==1)\n",
    "        \n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(ma.array(labels, mask=invert_masks).compressed())\n",
    "\n",
    "#     val_acc = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ae9ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 80, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 80, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 75, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 75, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 16 and 19 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a2a2acf9309d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtt_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_COL_COUNT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-a497239ef9b2>\u001b[0m in \u001b[0;36meval_batch\u001b[0;34m(classifier, model, val_dataset, batch_size, device, n_worker, MAX_COL_COUNT)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            n_workers=n_worker)\n\u001b[1;32m     11\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtable_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#pred, labels = eval_batch(table_batch, label_batch, mask_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/col2type/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/inf-bachpr-21-22-student-SennR-1952135/code/project/sato/model/datasets.py\u001b[0m in \u001b[0;36mgenerate_batches\u001b[0;34m(dataset, batch_size, shuffle, drop_last, device, n_workers)\u001b[0m\n\u001b[1;32m     75\u001b[0m                             pin_memory=False)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/col2type/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 80, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 80, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 75, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 75, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 16 and 19 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:689\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tt_list, prediction_list = eval_batch(classifier, model, val_dataset, batch_size, device, n_worker, MAX_COL_COUNT=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tt_list))\n",
    "print((len(prediction_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ef32e48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       889\n",
      "           1       0.72      0.32      0.45        65\n",
      "           2       0.97      0.94      0.95       199\n",
      "           3       0.98      0.99      0.99      7230\n",
      "           4       0.93      0.94      0.94      1535\n",
      "           5       0.89      0.80      0.84       288\n",
      "           6       0.93      0.91      0.92      2176\n",
      "           7       0.96      0.98      0.97        65\n",
      "           8       1.00      0.89      0.94        54\n",
      "           9       0.81      0.81      0.81       140\n",
      "          10       0.88      0.65      0.75        55\n",
      "          11       0.96      0.97      0.96      4012\n",
      "          12       0.96      0.97      0.96      5341\n",
      "          13       0.89      0.91      0.90      1598\n",
      "          14       0.96      0.84      0.89       101\n",
      "          15       0.93      0.96      0.95      2223\n",
      "          16       0.98      0.97      0.97      2702\n",
      "          17       0.96      0.83      0.89        88\n",
      "          18       0.84      0.69      0.76        81\n",
      "          19       0.97      0.93      0.95      1535\n",
      "          20       0.92      0.70      0.80       193\n",
      "          21       1.00      0.88      0.94        25\n",
      "          22       0.90      0.92      0.91      1803\n",
      "          23       0.98      0.93      0.95       606\n",
      "          24       0.91      0.77      0.83        39\n",
      "          25       0.93      0.88      0.90       138\n",
      "          26       0.94      0.90      0.92        71\n",
      "          27       0.97      0.87      0.91       588\n",
      "          28       0.90      0.90      0.90       136\n",
      "          29       0.96      0.96      0.96     11348\n",
      "          30       0.83      0.74      0.78        34\n",
      "          31       0.95      0.96      0.96       805\n",
      "          32       0.97      0.92      0.94        36\n",
      "          33       0.98      0.96      0.97       201\n",
      "          34       0.98      0.90      0.94       138\n",
      "          35       0.89      0.91      0.90       224\n",
      "          36       0.98      0.94      0.96       666\n",
      "          37       0.99      0.96      0.98       577\n",
      "          38       0.80      0.90      0.85       162\n",
      "          39       0.99      0.97      0.98       219\n",
      "          40       0.93      0.98      0.96       421\n",
      "          41       1.00      1.00      1.00       228\n",
      "          42       0.94      0.94      0.94       351\n",
      "          43       0.88      0.89      0.89       390\n",
      "          44       0.95      0.95      0.95      5368\n",
      "          45       0.76      0.82      0.79       159\n",
      "          46       0.96      0.97      0.96     16060\n",
      "          47       0.96      0.68      0.80        79\n",
      "          48       0.81      0.89      0.85      1661\n",
      "          49       0.81      0.54      0.65        39\n",
      "          50       0.89      0.80      0.84       247\n",
      "          51       0.95      0.91      0.93        22\n",
      "          52       0.89      0.87      0.88       208\n",
      "          53       0.92      0.85      0.89       191\n",
      "          54       0.84      0.37      0.52        43\n",
      "          55       0.95      0.91      0.93       209\n",
      "          56       0.94      0.91      0.92      2109\n",
      "          57       0.93      0.84      0.88       371\n",
      "          58       0.81      0.94      0.87       217\n",
      "          59       0.92      0.70      0.79        69\n",
      "          60       0.93      0.95      0.94      5164\n",
      "          61       0.61      0.19      0.29        58\n",
      "          62       0.86      0.84      0.85       333\n",
      "          63       1.00      1.00      1.00        38\n",
      "          64       1.00      0.54      0.70        35\n",
      "          65       0.97      0.96      0.96      2160\n",
      "          66       0.59      0.73      0.66        30\n",
      "          67       0.98      0.96      0.97       280\n",
      "          68       0.95      0.97      0.96       382\n",
      "          69       0.92      0.79      0.85        84\n",
      "          70       0.98      0.98      0.98      4424\n",
      "          71       0.98      0.97      0.97      4869\n",
      "          72       0.96      0.96      0.96      1041\n",
      "          73       0.97      0.97      0.97     10437\n",
      "          74       0.93      0.91      0.92       255\n",
      "          75       0.95      0.97      0.96      7395\n",
      "          76       0.98      0.98      0.98      3176\n",
      "          77       0.99      0.99      0.99      5353\n",
      "\n",
      "    accuracy                           0.96    122342\n",
      "   macro avg       0.92      0.87      0.89    122342\n",
      "weighted avg       0.96      0.96      0.95    122342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tt_list, prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed3a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n"
     ]
    }
   ],
   "source": [
    "print(valid_types[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb15716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write out data for further investigation\n",
    "# path_out_true_types = '../../combined/results/true_types'\n",
    "# path_out_predictions = '../../combined/results/predictions'\n",
    "\n",
    "# tt_df = pd.DataFrame(columns=['type'], data=tt_list)\n",
    "# tt_df.to_parquet(join(path_out_true_types, 'sato.parquet'))\n",
    "\n",
    "# pred_df = pd.DataFrame(columns=['type'], data=prediction_list)\n",
    "# pred_df.to_parquet(join(path_out_predictions, 'sato_sato.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
