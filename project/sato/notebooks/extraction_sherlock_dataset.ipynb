{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7858314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import re #for camel case conversion\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from os.path import join\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "import re #for camel case conversion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ['LDA_name'] = 'num-directstr_thr-0_tn-400'\n",
    "\n",
    "from extract.feature_extraction.topic_features_LDA import extract_topic_features\n",
    "from extract.feature_extraction.sherlock_features import extract_sherlock_features\n",
    "from utils import get_valid_types\n",
    "from model import models_sherlock\n",
    "from model.torchcrf import CRF\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7b0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case(s):\n",
    "  s = re.sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "  return ''.join([s[0].lower(), s[1:]])\n",
    "\n",
    "def sherlock_case(s):\n",
    "    s = re.sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "    s = ''.join([s[0].lower(), s[1:]])\n",
    "    s = ''.join(map(lambda x: x if x.islower() else \" \"+x, s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17eec6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = '../../sherlock/data/data/raw'\n",
    "path_processed = '../../sherlock/data/data/processed'\n",
    "path_out_true_types = '../../combined/results/true_types'\n",
    "path_out_predictions = '../../combined/results/predictions'\n",
    "path_out_temp = '../results/sato_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f33b0d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137353\n"
     ]
    }
   ],
   "source": [
    "# test_values = pd.read_parquet(join(path_raw, \"test_values.parquet\"))\n",
    "# train_values = pd.read_parquet(join(path_raw, \"train_values.parquet\"))\n",
    "validation_values = pd.read_parquet(join(path_raw, \"val_values.parquet\"))\n",
    "\n",
    "# print(len(test_values))\n",
    "# print(len(train_values))\n",
    "print(len(validation_values['values']))\n",
    "# test_labels = pd.read_parquet(join(path_raw, \"test_labels.parquet\"))\n",
    "# train_labels = pd.read_parquet(join(path_raw, \"train_labels.parquet\"))\n",
    "# validation_labels = pd.read_parquet(join(path_raw, \"val_labels.parquet\"))\n",
    "\n",
    "# test_processed = pd.read_parquet(join(path_processed, \"test.parquet\"))\n",
    "# train_processed = pd.read_parquet(join(path_processed, \"train.parquet\"))\n",
    "# validation_processed = pd.read_parquet(join(path_processed, \"validation.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c33f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = pd.concat([test_values, train_values, validation_values], ignore_index = True, axis = 0)\n",
    "# labels = pd.concat([test_labels, train_labels, validation_labels], ignore_index = True, axis = 0)\n",
    "# processed = pd.concat([test_processed, train_processed, validation_processed], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691cc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "# print(type(values)) \n",
    "# print(len(values))\n",
    "# print(len(processed))\n",
    "# labels.head(10)\n",
    "# print(len(labels))\n",
    "# labels.to_parquet(join(path_out_true_types, \"sherlock.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967a86e",
   "metadata": {},
   "source": [
    "### Sherlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f5803c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = SherlockModel();\n",
    "# model.model_files_directory = '../../../sherlock/model_files'\n",
    "# model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = model.predict(processed, \"sherlock\")\n",
    "# predicted_labels = pd.DataFrame(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d147f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels.columns = ['type']\n",
    "# predicted_labels.to_parquet(join(path_out_predictions, \"sherlock_sherlock.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d9aa9",
   "metadata": {},
   "source": [
    "### Sato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ffd1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'affiliate', 'affiliation', 'age', 'album', 'area', 'artist', 'birthDate', 'birthPlace', 'brand', 'capacity', 'category', 'city', 'class', 'classification', 'club', 'code', 'collection', 'command', 'company', 'component', 'continent', 'country', 'county', 'creator', 'credit', 'currency', 'day', 'depth', 'description', 'director', 'duration', 'education', 'elevation', 'family', 'fileSize', 'format', 'gender', 'genre', 'grades', 'isbn', 'industry', 'jockey', 'language', 'location', 'manufacturer', 'name', 'nationality', 'notes', 'operator', 'order', 'organisation', 'origin', 'owner', 'person', 'plays', 'position', 'product', 'publisher', 'range', 'rank', 'ranking', 'region', 'religion', 'requirement', 'result', 'sales', 'service', 'sex', 'species', 'state', 'status', 'symbol', 'team', 'teamName', 'type', 'weight', 'year']\n"
     ]
    }
   ],
   "source": [
    "TYPENAME = os.environ['TYPENAME']\n",
    "valid_types = get_valid_types(TYPENAME)\n",
    "print(valid_types)\n",
    "label_enc = LabelEncoder()\n",
    "label_enc.fit(valid_types)\n",
    "\n",
    "MAX_COL_COUNT = 10\n",
    "topic_dim = 400\n",
    "pre_trained_loc = './pretrained_sato'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"PyTorch device={}\".format(device))\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093a0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_cols = {}\n",
    "sherlock_feature_groups = ['char', 'word', 'par', 'rest']\n",
    "for f_g in sherlock_feature_groups:\n",
    "    feature_group_cols[f_g] = list(pd.read_csv(join(os.environ['BASEPATH'],\n",
    "                                          'configs', 'feature_groups', \n",
    "                                          \"{}_col.tsv\".format(f_g)),\n",
    "                                           sep='\\t', header=None, \n",
    "                                           index_col=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8179e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_vec = lambda x: np.pad(x, (0, topic_dim - len(x)),\n",
    "                    'constant',\n",
    "                    constant_values=(0.0, 1/topic_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb98491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(num_tags=78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = models_sherlock.build_sherlock(sherlock_feature_groups, num_classes=len(valid_types), topic_dim=topic_dim, dropout_ratio=0.35)\n",
    "#classifier.load_state_dict(torch.load(join(pre_trained_loc, 'sherlock_None.pt'), map_location=device))\n",
    "model = CRF(len(valid_types) , batch_first=True).to(device)\n",
    "#model.load_state_dict(torch.load(join(pre_trained_loc, 'model.pt'), map_location=device))\n",
    "\n",
    "loaded_params = torch.load(join(pre_trained_loc, 'model.pt'), map_location=device)\n",
    "classifier.load_state_dict(loaded_params['col_classifier'])\n",
    "model.load_state_dict(loaded_params['CRF_model'])\n",
    "\n",
    "classifier.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c93e730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "\n",
    "    df_dic = {'df':df, 'locator':'None', 'dataset_id':'None'}\n",
    "    feature_dic = {}\n",
    "    n = df.shape[1]\n",
    "\n",
    "    # topic vectors\n",
    "    topic_features = extract_topic_features(df_dic)\n",
    "    topic_vec = pad_vec(topic_features.loc[0,'table_topic'])\n",
    "    feature_dic['topic'] = torch.FloatTensor(np.vstack((np.tile(topic_vec,(n,1)), np.zeros((MAX_COL_COUNT - n, topic_dim)))))\n",
    "\n",
    "\n",
    "    # sherlock vectors\n",
    "    sherlock_features = extract_sherlock_features(df_dic)\n",
    "    for f_g in feature_group_cols:\n",
    "        temp = sherlock_features[feature_group_cols[f_g]].to_numpy()\n",
    "        temp = np.vstack((temp, np.zeros((MAX_COL_COUNT - n, temp.shape[1])))).astype('float')\n",
    "        temp = np.nan_to_num(temp)\n",
    "        feature_dic[f_g] = torch.FloatTensor(temp)\n",
    "\n",
    "    # dictionary of features, labels, masks\n",
    "    return feature_dic, np.zeros(MAX_COL_COUNT), torch.tensor([1]*n + [0]*(MAX_COL_COUNT-n), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93250f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "\n",
    "    feature_dic, labels, mask = extract(df)\n",
    "\n",
    "    emissions = classifier(feature_dic).view(1, MAX_COL_COUNT, -1)\n",
    "    mask = mask.view(1, MAX_COL_COUNT)\n",
    "    pred = model.decode(emissions, mask)[0]\n",
    "\n",
    "    return label_enc.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39478f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [] #pd.DataFrame(columns=['type'])\n",
    "write_out_limit = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8ff01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/pandas/core/strings/object_array.py:90: FutureWarning: Possible nested set at position 1\n",
      "  regex = re.compile(pat, flags=flags)\n",
      "/home/senn/virtualenvs/col2type/lib/python3.7/site-packages/pandas/core/strings/object_array.py:90: FutureWarning: Possible nested set at position 1\n",
      "  regex = re.compile(pat, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122099\n",
      "122199\n",
      "122299\n",
      "122399\n",
      "122499\n",
      "122599\n",
      "122699\n",
      "122799\n",
      "122899\n",
      "122999\n",
      "123099\n",
      "123199\n",
      "123299\n",
      "123399\n",
      "123499\n",
      "123599\n",
      "123699\n",
      "123799\n",
      "123899\n",
      "123999\n",
      "writing out predictions...\n",
      "124099\n",
      "124199\n",
      "124299\n",
      "124399\n",
      "124499\n",
      "124599\n",
      "124699\n",
      "124799\n",
      "124899\n",
      "124999\n",
      "125099\n",
      "125199\n",
      "125299\n",
      "125399\n",
      "125499\n",
      "125599\n",
      "125699\n",
      "125799\n",
      "125899\n",
      "125999\n",
      "writing out predictions...\n",
      "126099\n",
      "126199\n",
      "126299\n",
      "126399\n",
      "126499\n",
      "126599\n",
      "126699\n",
      "126799\n",
      "126899\n",
      "126999\n",
      "127099\n",
      "127199\n",
      "127299\n",
      "127399\n",
      "127499\n",
      "127599\n",
      "127699\n",
      "127799\n",
      "127899\n",
      "127999\n",
      "writing out predictions...\n",
      "128099\n",
      "128199\n",
      "128299\n",
      "128399\n",
      "128499\n",
      "128599\n",
      "128699\n",
      "128799\n",
      "128899\n",
      "128999\n",
      "129099\n",
      "129199\n",
      "129299\n",
      "129399\n",
      "129499\n",
      "129599\n",
      "129699\n",
      "129799\n",
      "129899\n",
      "129999\n",
      "writing out predictions...\n",
      "130099\n",
      "130199\n",
      "130299\n",
      "130399\n",
      "130499\n",
      "130599\n",
      "130699\n",
      "130799\n",
      "130899\n",
      "130999\n",
      "131099\n",
      "131199\n",
      "131299\n",
      "131399\n",
      "131499\n",
      "131599\n",
      "131699\n",
      "131799\n",
      "131899\n",
      "131999\n",
      "writing out predictions...\n",
      "132099\n",
      "132199\n",
      "132299\n",
      "132399\n",
      "132499\n",
      "132599\n",
      "132699\n",
      "132799\n",
      "132899\n",
      "132999\n",
      "133099\n",
      "133199\n",
      "133299\n",
      "133399\n",
      "133499\n",
      "133599\n",
      "133699\n",
      "133799\n",
      "133899\n",
      "133999\n",
      "writing out predictions...\n",
      "134099\n",
      "134199\n",
      "134299\n",
      "134399\n",
      "134499\n",
      "134599\n",
      "134699\n",
      "134799\n",
      "134899\n",
      "134999\n",
      "135099\n",
      "135199\n",
      "135299\n",
      "135399\n",
      "135499\n",
      "135599\n",
      "135699\n",
      "135799\n",
      "135899\n",
      "135999\n",
      "writing out predictions...\n",
      "136099\n",
      "136199\n",
      "136299\n",
      "136399\n",
      "136499\n",
      "136599\n",
      "136699\n",
      "136799\n",
      "136899\n",
      "136999\n",
      "137099\n",
      "137199\n",
      "137299\n"
     ]
    }
   ],
   "source": [
    "write_out_idx = 0\n",
    "for idx, col in enumerate(validation_values['values']):\n",
    "    col = ast.literal_eval(col)\n",
    "    df = pd.DataFrame(columns=['col'], data=col)\n",
    "    prediction = evaluate(df)\n",
    "    predicted_labels.extend(prediction)\n",
    "    df = None\n",
    "#     true_types.extend(df_header)\n",
    "    if((idx+1) % 100 == 0):\n",
    "        print(idx)\n",
    "    if ((idx+1) % write_out_limit == 0):\n",
    "        # write out predictions to parquet file\n",
    "        print(\"writing out predictions...\")\n",
    "        df_pred = pd.DataFrame(data=predicted_labels, columns=['predicted_type'])\n",
    "        # write out predictions, format: model_dataset_tableCount_writeOutCount.parquet\n",
    "        df_pred.to_parquet(join(path_out_temp, 'sato_sherlock_'+ str(idx) + '_' +str(write_out_idx)+ '.parquet'))\n",
    "        write_out_idx += 1\n",
    "        predicted_labels = []\n",
    "        df_pred = None\n",
    "            \n",
    "df_pred = pd.DataFrame(predicted_labels, columns=['predicted_type'])\n",
    "df_pred.to_parquet(join(path_out_temp, 'sato_sherlock_'+ str(idx) + '_' +str(write_out_idx)+ '.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c130e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c092790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            type\n",
      "137348      name\n",
      "137349   address\n",
      "137350  duration\n",
      "137351     class\n",
      "137352      name\n"
     ]
    }
   ],
   "source": [
    "files = listdir(path_out_temp)\n",
    "files.sort(key=lambda x: int(x.split('_')[2]))\n",
    "# print(files)\n",
    "df_combined = pd.DataFrame()\n",
    "for file in files:\n",
    "    filepath = os.path.join(path_out_temp, file)\n",
    "    df_partial = pd.read_parquet(filepath)\n",
    "    df_combined = pd.concat([df_combined, df_partial], ignore_index=True, sort=False)\n",
    "\n",
    "df_combined.columns = ['type']\n",
    "print(df_combined.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb79fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff9599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['type'], data=predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbfefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_parquet(join(path_out_predictions, \"sato_sherlock_validation_137353.parquet\"))\n",
    "# df_combined.to_parquet(join(path_out_predictions, \"sato_sherlock_validation.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
