{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-03-28 19:41:48.448525\n",
      "Load data (train) process took 0:00:07.321858 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-03-28 19:41:56.040150\n",
      "Load data (validation) process took 0:00:01.001728 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-03-28 19:41:57.074744\n",
      "Finished at 2022-03-28 19:41:58.048018, took 0:00:00.973293 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: load Sherlock with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0328 19:41:58.084947 140316294813504 deprecation.py:506] From /home/senn/virtualenvs/sherlock/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0328 19:41:58.085757 140316294813504 deprecation.py:506] From /home/senn/virtualenvs/sherlock/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0328 19:41:58.088379 140316294813504 deprecation.py:506] From /home/senn/virtualenvs/sherlock/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0328 19:41:58.101621 140316294813504 deprecation.py:506] From /home/senn/virtualenvs/sherlock/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-03-28 19:41:58.071903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:41:58.466867: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-03-28 19:41:58.490058: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3193915000 Hz\n",
      "2022-03-28 19:41:58.490786: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ff43287950 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-28 19:41:58.490808: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model.\n",
      "Finished at 2022-03-28 19:41:58.694472, took 0:00:00.622580 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "model = SherlockModel();\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");\n",
    "\n",
    "print('Initialized model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: fit Sherlock from scratch (and save for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"retrained_sherlock_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = datetime.now()\n",
    "# print(f'Started at {start}')\n",
    "\n",
    "# model = SherlockModel()\n",
    "# # Model will be stored with ID `model_id`\n",
    "# model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "# print('Trained and saved new model.')\n",
    "# print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 137353, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8951410029373902"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "# model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "grades\t\t0.993\t\t0.993\t\t0.993\t\t1765\n",
      "isbn\t\t0.991\t\t0.993\t\t0.988\t\t1430\n",
      "jockey\t\t0.985\t\t0.982\t\t0.988\t\t2819\n",
      "industry\t0.984\t\t0.983\t\t0.985\t\t2958\n",
      "birth date\t0.977\t\t0.985\t\t0.969\t\t479\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "rank\t\t0.693\t\t0.625\t\t0.778\t\t2983\n",
      "person\t\t0.664\t\t0.717\t\t0.618\t\t579\n",
      "director\t0.568\t\t0.591\t\t0.547\t\t225\n",
      "sales\t\t0.556\t\t0.586\t\t0.528\t\t322\n",
      "ranking\t\t0.441\t\t0.753\t\t0.312\t\t439\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       address      0.931     0.943     0.937      3003\n",
      "     affiliate      0.943     0.809     0.871       204\n",
      "   affiliation      0.973     0.957     0.965      1768\n",
      "           age      0.866     0.950     0.906      3033\n",
      "         album      0.892     0.889     0.890      3035\n",
      "          area      0.870     0.820     0.844      1987\n",
      "        artist      0.816     0.873     0.844      3043\n",
      "    birth date      0.985     0.969     0.977       479\n",
      "   birth place      0.934     0.921     0.928       418\n",
      "         brand      0.830     0.671     0.742       574\n",
      "      capacity      0.793     0.721     0.755       362\n",
      "      category      0.924     0.890     0.906      3087\n",
      "          city      0.864     0.904     0.883      2966\n",
      "         class      0.901     0.915     0.908      2971\n",
      "classification      0.927     0.862     0.893       587\n",
      "          club      0.974     0.955     0.964      2977\n",
      "          code      0.916     0.907     0.912      2956\n",
      "    collection      0.984     0.931     0.957       476\n",
      "       command      0.938     0.904     0.921      1045\n",
      "       company      0.912     0.888     0.900      3041\n",
      "     component      0.888     0.880     0.884      1226\n",
      "     continent      0.875     0.894     0.885       227\n",
      "       country      0.892     0.950     0.920      3038\n",
      "        county      0.943     0.957     0.950      2959\n",
      "       creator      0.770     0.841     0.804       347\n",
      "        credit      0.868     0.813     0.840       941\n",
      "      currency      0.982     0.968     0.975       405\n",
      "           day      0.953     0.892     0.921      3038\n",
      "         depth      0.931     0.916     0.923       947\n",
      "   description      0.804     0.869     0.835      3042\n",
      "      director      0.591     0.547     0.568       225\n",
      "      duration      0.924     0.948     0.936      3000\n",
      "     education      0.856     0.818     0.837       313\n",
      "     elevation      0.956     0.946     0.951      1299\n",
      "        family      0.964     0.895     0.928       746\n",
      "     file size      0.941     0.845     0.891       361\n",
      "        format      0.966     0.959     0.963      2956\n",
      "        gender      0.868     0.721     0.788      1030\n",
      "         genre      0.965     0.952     0.958      1163\n",
      "        grades      0.993     0.993     0.993      1765\n",
      "      industry      0.983     0.985     0.984      2958\n",
      "          isbn      0.993     0.988     0.991      1430\n",
      "        jockey      0.982     0.988     0.985      2819\n",
      "      language      0.939     0.953     0.946      1474\n",
      "      location      0.896     0.827     0.861      2949\n",
      "  manufacturer      0.865     0.819     0.841       945\n",
      "          name      0.724     0.759     0.741      3017\n",
      "   nationality      0.907     0.691     0.784       424\n",
      "         notes      0.724     0.842     0.779      2303\n",
      "      operator      0.794     0.847     0.819       404\n",
      "         order      0.869     0.887     0.878      1462\n",
      "  organisation      0.832     0.832     0.832       262\n",
      "        origin      0.947     0.900     0.923      1439\n",
      "         owner      0.931     0.869     0.899      1673\n",
      "        person      0.717     0.618     0.664       579\n",
      "         plays      0.846     0.903     0.873      1513\n",
      "      position      0.806     0.839     0.822      3057\n",
      "       product      0.868     0.878     0.873      2647\n",
      "     publisher      0.888     0.899     0.893       880\n",
      "         range      0.855     0.759     0.804       577\n",
      "          rank      0.625     0.778     0.693      2983\n",
      "       ranking      0.753     0.312     0.441       439\n",
      "        region      0.882     0.810     0.845      2740\n",
      "      religion      0.972     0.921     0.946       340\n",
      "   requirement      0.927     0.807     0.863       300\n",
      "        result      0.962     0.940     0.951      2920\n",
      "         sales      0.586     0.528     0.556       322\n",
      "       service      0.964     0.925     0.944      2222\n",
      "           sex      0.903     0.945     0.924      2997\n",
      "       species      0.921     0.950     0.935       819\n",
      "         state      0.939     0.957     0.948      3030\n",
      "        status      0.943     0.936     0.940      3100\n",
      "        symbol      0.958     0.946     0.952      1752\n",
      "          team      0.850     0.870     0.860      3011\n",
      "     team name      0.893     0.827     0.859      1639\n",
      "          type      0.916     0.875     0.895      2909\n",
      "        weight      0.958     0.931     0.944      2963\n",
      "          year      0.965     0.937     0.951      3015\n",
      "\n",
      "      accuracy                          0.895    137353\n",
      "     macro avg      0.890     0.866     0.876    137353\n",
      "  weighted avg      0.898     0.895     0.895    137353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[440] expected \"state\" but predicted \"sales\"\n",
      "[596] expected \"state\" but predicted \"age\"\n",
      "[1486] expected \"state\" but predicted \"genre\"\n",
      "[2917] expected \"state\" but predicted \"class\"\n",
      "[4028] expected \"state\" but predicted \"classification\"\n",
      "[5153] expected \"state\" but predicted \"country\"\n",
      "[6938] expected \"state\" but predicted \"city\"\n",
      "[7375] expected \"state\" but predicted \"owner\"\n",
      "[7766] expected \"state\" but predicted \"creator\"\n",
      "[8789] expected \"state\" but predicted \"origin\"\n",
      "[8997] expected \"state\" but predicted \"type\"\n",
      "[10567] expected \"state\" but predicted \"team\"\n",
      "[10660] expected \"state\" but predicted \"team name\"\n",
      "[11128] expected \"state\" but predicted \"city\"\n",
      "[13568] expected \"state\" but predicted \"region\"\n",
      "[14893] expected \"state\" but predicted \"origin\"\n",
      "[19061] expected \"state\" but predicted \"ranking\"\n",
      "[19412] expected \"state\" but predicted \"region\"\n",
      "[19896] expected \"state\" but predicted \"year\"\n",
      "[21010] expected \"state\" but predicted \"country\"\n",
      "[21514] expected \"state\" but predicted \"country\"\n",
      "[24489] expected \"state\" but predicted \"birth place\"\n",
      "[24774] expected \"state\" but predicted \"name\"\n",
      "[25566] expected \"state\" but predicted \"city\"\n",
      "[25760] expected \"state\" but predicted \"county\"\n",
      "[25974] expected \"state\" but predicted \"area\"\n",
      "[27086] expected \"state\" but predicted \"location\"\n",
      "[29528] expected \"state\" but predicted \"year\"\n",
      "[32151] expected \"state\" but predicted \"city\"\n",
      "[32615] expected \"state\" but predicted \"city\"\n",
      "[34979] expected \"state\" but predicted \"class\"\n",
      "[36718] expected \"state\" but predicted \"rank\"\n",
      "[36825] expected \"state\" but predicted \"city\"\n",
      "[36904] expected \"state\" but predicted \"status\"\n",
      "[37525] expected \"state\" but predicted \"team name\"\n",
      "[39109] expected \"state\" but predicted \"origin\"\n",
      "[40194] expected \"state\" but predicted \"age\"\n",
      "[44636] expected \"state\" but predicted \"county\"\n",
      "[46516] expected \"state\" but predicted \"city\"\n",
      "[48339] expected \"state\" but predicted \"team\"\n",
      "[49965] expected \"state\" but predicted \"country\"\n",
      "[50258] expected \"state\" but predicted \"county\"\n",
      "[50912] expected \"state\" but predicted \"team\"\n",
      "[53191] expected \"state\" but predicted \"status\"\n",
      "[53892] expected \"state\" but predicted \"country\"\n",
      "[54459] expected \"state\" but predicted \"country\"\n",
      "[54670] expected \"state\" but predicted \"area\"\n",
      "[55158] expected \"state\" but predicted \"team\"\n",
      "[64204] expected \"state\" but predicted \"city\"\n",
      "[65643] expected \"state\" but predicted \"team\"\n",
      "[66552] expected \"state\" but predicted \"county\"\n",
      "[67466] expected \"state\" but predicted \"status\"\n",
      "[68209] expected \"state\" but predicted \"origin\"\n",
      "[68264] expected \"state\" but predicted \"city\"\n",
      "[69707] expected \"state\" but predicted \"status\"\n",
      "[71176] expected \"state\" but predicted \"code\"\n",
      "[71835] expected \"state\" but predicted \"county\"\n",
      "[73172] expected \"state\" but predicted \"country\"\n",
      "[73789] expected \"state\" but predicted \"area\"\n",
      "[74164] expected \"state\" but predicted \"country\"\n",
      "[74230] expected \"state\" but predicted \"region\"\n",
      "[75551] expected \"state\" but predicted \"country\"\n",
      "[80554] expected \"state\" but predicted \"notes\"\n",
      "[84103] expected \"state\" but predicted \"city\"\n",
      "[84182] expected \"state\" but predicted \"notes\"\n",
      "[84252] expected \"state\" but predicted \"country\"\n",
      "[85354] expected \"state\" but predicted \"origin\"\n",
      "[85489] expected \"state\" but predicted \"country\"\n",
      "[85766] expected \"state\" but predicted \"origin\"\n",
      "[86889] expected \"state\" but predicted \"origin\"\n",
      "[88299] expected \"state\" but predicted \"artist\"\n",
      "[89474] expected \"state\" but predicted \"team\"\n",
      "[89536] expected \"state\" but predicted \"year\"\n",
      "[91499] expected \"state\" but predicted \"rank\"\n",
      "[91759] expected \"state\" but predicted \"country\"\n",
      "[93713] expected \"state\" but predicted \"country\"\n",
      "[94088] expected \"state\" but predicted \"city\"\n",
      "[94890] expected \"state\" but predicted \"team name\"\n",
      "[95244] expected \"state\" but predicted \"artist\"\n",
      "[95309] expected \"state\" but predicted \"team name\"\n",
      "[95351] expected \"state\" but predicted \"origin\"\n",
      "[95648] expected \"state\" but predicted \"region\"\n",
      "[97715] expected \"state\" but predicted \"county\"\n",
      "[97789] expected \"state\" but predicted \"team\"\n",
      "[99094] expected \"state\" but predicted \"team\"\n",
      "[99600] expected \"state\" but predicted \"rank\"\n",
      "[99910] expected \"state\" but predicted \"sales\"\n",
      "[102405] expected \"state\" but predicted \"age\"\n",
      "[103938] expected \"state\" but predicted \"class\"\n",
      "[104265] expected \"state\" but predicted \"depth\"\n",
      "[104425] expected \"state\" but predicted \"origin\"\n",
      "[104689] expected \"state\" but predicted \"brand\"\n",
      "[105788] expected \"state\" but predicted \"origin\"\n",
      "[107014] expected \"state\" but predicted \"origin\"\n",
      "[107346] expected \"state\" but predicted \"area\"\n",
      "[108261] expected \"state\" but predicted \"weight\"\n",
      "[108726] expected \"state\" but predicted \"team\"\n",
      "[108990] expected \"state\" but predicted \"origin\"\n",
      "[110032] expected \"state\" but predicted \"team\"\n",
      "[112118] expected \"state\" but predicted \"day\"\n",
      "[112456] expected \"state\" but predicted \"class\"\n",
      "[112874] expected \"state\" but predicted \"county\"\n",
      "[113559] expected \"state\" but predicted \"city\"\n",
      "[114211] expected \"state\" but predicted \"country\"\n",
      "[114580] expected \"state\" but predicted \"symbol\"\n",
      "[114950] expected \"state\" but predicted \"year\"\n",
      "[115413] expected \"state\" but predicted \"region\"\n",
      "[118127] expected \"state\" but predicted \"area\"\n",
      "[119952] expected \"state\" but predicted \"age\"\n",
      "[120300] expected \"state\" but predicted \"type\"\n",
      "[120610] expected \"state\" but predicted \"sex\"\n",
      "[120955] expected \"state\" but predicted \"rank\"\n",
      "[121935] expected \"state\" but predicted \"team\"\n",
      "[121964] expected \"state\" but predicted \"city\"\n",
      "[122401] expected \"state\" but predicted \"rank\"\n",
      "[123211] expected \"state\" but predicted \"origin\"\n",
      "[124135] expected \"state\" but predicted \"family\"\n",
      "[128060] expected \"state\" but predicted \"region\"\n",
      "[128284] expected \"state\" but predicted \"symbol\"\n",
      "[129507] expected \"state\" but predicted \"region\"\n",
      "[130489] expected \"state\" but predicted \"credit\"\n",
      "[130769] expected \"state\" but predicted \"position\"\n",
      "[130959] expected \"state\" but predicted \"origin\"\n",
      "[131723] expected \"state\" but predicted \"city\"\n",
      "[131776] expected \"state\" but predicted \"country\"\n",
      "[132196] expected \"state\" but predicted \"age\"\n",
      "[133322] expected \"state\" but predicted \"city\"\n",
      "[136181] expected \"state\" but predicted \"operator\"\n",
      "[136444] expected \"state\" but predicted \"language\"\n",
      "Total mismatches: 14419 (F1 score: 0.8951410029373902)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 727),\n",
       " ('rank', 663),\n",
       " ('region', 521),\n",
       " ('location', 509),\n",
       " ('position', 491),\n",
       " ('description', 400),\n",
       " ('team', 390),\n",
       " ('artist', 385),\n",
       " ('notes', 364),\n",
       " ('type', 363),\n",
       " ('area', 357),\n",
       " ('category', 341),\n",
       " ('company', 340),\n",
       " ('album', 338),\n",
       " ('day', 329),\n",
       " ('product', 322),\n",
       " ('ranking', 302),\n",
       " ('gender', 287),\n",
       " ('city', 286),\n",
       " ('team name', 283),\n",
       " ('code', 274),\n",
       " ('class', 253),\n",
       " ('person', 221),\n",
       " ('owner', 219),\n",
       " ('weight', 203),\n",
       " ('status', 197),\n",
       " ('brand', 189),\n",
       " ('year', 189),\n",
       " ('credit', 176),\n",
       " ('result', 174),\n",
       " ('manufacturer', 171),\n",
       " ('address', 171),\n",
       " ('service', 167),\n",
       " ('order', 165),\n",
       " ('sex', 164),\n",
       " ('duration', 155),\n",
       " ('age', 153),\n",
       " ('sales', 152),\n",
       " ('country', 152),\n",
       " ('plays', 147),\n",
       " ('component', 147),\n",
       " ('origin', 144),\n",
       " ('range', 139),\n",
       " ('club', 133),\n",
       " ('nationality', 131),\n",
       " ('state', 129),\n",
       " ('county', 127),\n",
       " ('format', 120),\n",
       " ('director', 102),\n",
       " ('capacity', 101),\n",
       " ('command', 100),\n",
       " ('symbol', 94),\n",
       " ('publisher', 89),\n",
       " ('classification', 81),\n",
       " ('depth', 80),\n",
       " ('family', 78),\n",
       " ('affiliation', 76),\n",
       " ('elevation', 70),\n",
       " ('language', 69),\n",
       " ('operator', 62),\n",
       " ('requirement', 58),\n",
       " ('education', 57),\n",
       " ('file size', 56),\n",
       " ('genre', 56),\n",
       " ('creator', 55),\n",
       " ('industry', 44),\n",
       " ('organisation', 44),\n",
       " ('species', 41),\n",
       " ('affiliate', 39),\n",
       " ('jockey', 33),\n",
       " ('collection', 33),\n",
       " ('birth place', 33),\n",
       " ('religion', 27),\n",
       " ('continent', 24),\n",
       " ('isbn', 17),\n",
       " ('birth date', 15),\n",
       " ('currency', 13),\n",
       " ('grades', 12)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('state'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"address\", actual label \"address\". Actual values:\n",
      "[['Cabot House', 'Cabot House', '5 Hill Rd.', '5 Hill Rd.', '9 Cabot Rd.', '9 Cabot Rd.', 'Cabot House', '22 Bank Rd.', '22 Bank Rd.', 'Cabot House', '31 Bank Rd.', '31 Bank Rd.', 'Bairds Hotel', '11 Cabot Rd.', '11 Cabot Rd.', '10 Hill Rd.', '10 Hill Rd.', '10 Hill Rd.', '10 Hill Rd.', '7A Church Rd.', '1 Cabot Rd.', '1 Cabot Rd.', '1 Cabot Rd.', '1 Cabot Rd.', '2 Coronation St.', '2 Coronation St.', '7A Church Rd.', '12 Hill Rd.', '12 Hill Rd.', '12 Hill Rd.', 'Cabot House', '19 Bank Rd.', '19 Bank Rd.', '19 Bank Rd.', '19 Bank Rd.', '19 Bank Rd.', '7A Church Rd.', '18 Mill Rd.', '17 Hill Rd.', '17 Hill Rd.', 'Cabot House', 'Cabot House', '25 Bank Rd.', '10 Coronation St.', '6 Cabot Rd.', '6 Cabot Rd.', '8 Hill Rd.', '8 Hill Rd.', '4 Mill Rd.', '4 Mill Rd.', '12 Sulva Rd.', '4 Haig Rd.', '13 Botwood Rd.', '13 Botwood Rd.', '8 Botwood Rd.', '8 Botwood Rd.', '16 Botwood Rd.', '16 Botwood Rd.', '16 Botwood Rd.', '16 Botwood Rd.', '56 Beaumont Ave.', '8 Botwood Rd.', '56 Beaumont Ave.', '61 Botwood Rd.', '8 Botwood Rd.', '8 Botwood Rd.', '41 Beaumont Ave.', '41 Beaumont Ave.', '1 Polygon Rd.', '1 Polygon Rd.', '1 Polygon Rd.', '8 Botwood Rd.', '8 Botwood Rd.', '40 Botwood Rd.', '40 Botwood Rd.', '11 Haig Rd.', '11 Haig Rd.', '40 Botwood Rd.', '43 Botwood Rd.', '56 Botwood Rd.', '56 Botwood Rd.', '56 Botwood Rd.', '56 Botwood Rd.', '55 Botwood Rd.', '55 Botwood Rd.', '55 Botwood Rd.', '55 Botwood Rd.', '9 Botwood Rd.', '9 Botwood Rd.', '51 Botwood Rd.', '51 Botwood Rd.', '33 Botwood Rd.', '33 Botwood Rd.', '33 Botwood Rd.', '33 Botwood Rd.', '17 Sulva Rd.', '17 Sulva Rd.', '1 Sulva Rd.', '1 Sulva Rd.', '5B Botwood Rd.', '21 Monchy Rd.', '15 Junction Rd.', '15 Junction Rd.', '15 Junction Rd.', '15 Junction Rd.', '11 Monchy Rd.', '49 Queen St.', '17 Monchy Rd.', '17 Monchy Rd.', '49 Queen St.', '49 Junction Rd.', '49 Junction Rd.', '1 Queen St.', '1 Queen St.', '37 Monchy Rd.', '37 Monchy Rd.', 'Pine Ave Apt. 5', 'Pine Ave Apt. 5', '6 Peronne Rd.', '2 Peronne Rd.', '6 Peronne Rd.', '7 Peronne Rd.', '7 Peronne Rd.', '7 Peronne Rd.', 'Pine Ave. Apt. 19', '13 Queen St.', 'Pine Ave. Apt. 19', '41 Junction Rd.', '13 Queen St.', '4 Pine Ave.', '51 Junction Rd.', '51 Junction Rd.', '6 Monchy Rd.', '6 Monchy Rd.', '1 Peronne Rd.', '1 Peronne Rd.', 'Pine Ave. Apt. 6', 'Pine Ave. Apt. 6', '50 Junction Rd.', '20 Junction Rd.', '20 Junction Rd.', '20 Junction Rd.', 'Pine Ave. Apt. 15', 'Pine Ave. Apt. 15', '23 Monchy Rd.', '23 Monchy Rd.', '5 Peronne Rd.', '15 Queen St.', '15 Queen St.', '15 Queen St.', '24 East St.', '13 East St.', '13 East St.', '4 Railway Rd.', '4 Railway Rd.', '12 Fourth Ave.', '12 Fourth Ave.', '8 Circular Rd.', '8 Circular Rd.', '8 Circular Rd.', '17 Circular Rd.', '17 Circular Rd.', '1A Valley Rd.', '28 Fourth Ave.', '28 Fourth Ave.', '22 East St.', '22 East St.', '15 Fourth Ave.', '11 Third Ave.', '15 Fourth Ave.', '15 Fourth Ave.', '15 Fourth Ave.', '11 Third Ave.', '15 Fourth Ave.', '4 Railway Rd.', '6 Valley Rd.', '4 Railway Rd.', '6 Valley Rd.', '7 West St.', '7 West St.', '22 Circular Rd.', '25 Fourth Ave.', '5 Valley Rd.', '25 Fourth Ave.', '5 Valley Rd.', '5 Fourth Ave.', '5 Fourth Ave.', '15 Valley Rd.', '1 Third Ave.', '1 Third Ave.', '1 Third Ave.', '20 Fourth Ave.', '10 Valley Rd.', '20 Fourth Ave.', '20 Fourth Ave.', '11 East St.', '20 Fourth Ave.', '11 East St.', '2 Railway Rd.', '20 Fourth Ave.', '10 Valley Rd.', '11 East St.', '2 Railway Rd.', '20 East St.', '20 East St.', '20 East St.', '20 East St.', '20 East St.', '10 East St.', '10 East St.', '10 East St.', '11 Railway Rd.', '7 Circular Rd.', '11 Railway Rd.', '11 Railway Rd.', '7 Circular Rd.', '11 Railway Rd.', '3 Fourth Ave.', '13 Fourth Ave.', '4 Third Ave.', '3 Fourth Ave.', '13 Fourth Ave.', '13 Fourth Ave.', '13 Fourth Ave.', '11 Third Ave.', '11 Third Ave.', '13 Fourth Ave.', '3 Fourth Ave.', '10 Circular Rd.', '10 Circular Rd.', '12 Third Ave.', '10 Circular Rd.', '10 Circular Rd.', '12 Third Ave.', '10 Circular Rd.', '5 Railway Rd.', '5 Railway Rd.', '7 Third Ave.', '14 Fourth Ave.', '14 Fourth Ave.', '14 Fourth Ave.', '7 Third Ave.', '14 Fourth Ave.', '14 Fourth Ave.', '14 Fourth Ave.', '26 East St.', '26 East St.', '5 East St.', '5 East St.', '5 East St.', '16 East St.', '15 Third Ave.', '7 Valley Rd.', '15 Third Ave.', '15 Third Ave.', '7 Valley Rd.', '1 Railway Rd.', '1 Railway Rd.', '33 Circular Rd.', '33 Circular Rd.', '33 Circular Rd.', '18 East St.', '18 East St.', '6 Third Ave.', '6 Third Ave.', '25 Circular Rd.', '5 Valley Rd.', '23 Fourth Ave.', '23 Fourth Ave.', '1A Valley Rd.', '37 Circular Rd.', '23 Fourth Ave.', '37 Circular Rd.', '1A Valley Rd.', '24A Fourth Ave.', '24A Fourth Ave.', '1 Fourth Ave.', '1 Fourth Ave.', '1 Fourth Ave.', '2A Valley Rd.', '2A Valley Rd.', '6 Valley Rd.', '30 Fourth Ave.', '30 Fourth Ave.', '19 Fourth Ave.', '19 Fourth Ave.', '3 Valley Rd.', '3 Valley Rd.']]\n",
      "Finished at 2022-03-28 19:42:11.068120\n"
     ]
    }
   ],
   "source": [
    "idx = 1001\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')\n",
    "\n",
    "print(f'Finished at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
